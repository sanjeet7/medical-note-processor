# Medical Note Processing System - README

> **Part of take-home assessment for healthcare AI engineer position**

Complete implementation guide for a production-grade medical note processing system with FastAPI, RAG, agent-based extraction, FHIR conversion, and comprehensive testing.

---

## ğŸ“‹ Table of Contents

- [Overview](#overview)
- [Features](#features)
- [Getting Started](#getting-started)
- [Implementation Plan](#implementation-plan)
- [Testing](#testing)
- [API Documentation](#api-documentation)
- [Project Structure](#project-structure)

---

## ğŸ¯ Overview

This system automates medical document processing workflows through:
- **FastAPI backend** with PostgreSQL database
- **LLM integration** for summarization (provider-agnostic: OpenAI, Ollama)
- **RAG pipeline** for medical guideline Q&A
- **Agent-based extraction** with NIH API integration (ICD-10, RxNorm)
- **FHIR conversion** using fhir.resources library
- **Docker deployment** with docker-compose

---

## âœ¨ Features

### Part 1: FastAPI Backend
- âœ… Health check endpoint
- âœ… Full- **CRUD Operations**: Full create, read, update, delete support with validation
- **Partial Updates**: PUT endpoint supports updating only specific fields
- **Database Seeding**: 6 sample SOAP notes included

### Part 2 LLM Integration:
- OpenAI and Anthropic provider support
- `/summarize_note` - Summarize medical notes using LLM
- `/query_note` - Ask specific questions about medical notes
- Response caching to reduce API costs
- Document ID or raw text input support

### Part 3: RAG Pipeline
- âœ… Medical guidelines knowledge base
- âœ… Smart chunking (500 tokens, 100 overlap)
- âœ… ChromaDB vector store
- âœ… LLM-based reranking
- âœ… Source citations in answers

### Part 4: Agent System
- âœ… Entity extraction (patient, conditions, medications, vitals)
- âœ… ICD-10 code lookup via NIH API
- âœ… RxNorm code lookup via NIH API
- âœ… Trajectory logging
- âœ… Comprehensive unit tests

### Part 5: FHIR Conversion
- âœ… FHIR resource mapping (Patient, Condition, MedicationRequest, Observation, Procedure, CarePlan)
- âœ… FHIR Bundle creation
- âœ… Spec-compliant using fhir.resources library

### Part 6: Containerization
- âœ… Multi-stage Dockerfile
- âœ… Docker Compose orchestration
- âœ… Database persistence
- âœ… Auto-seeding and indexing
- âœ… Hot-reloading for development
- âœ… Makefile for common operations

---

## ğŸš€ Quick Start

### Prerequisites
- Docker & Docker Compose
- OpenAI API key (or local Ollama instance)

### Setup

1. **Clone & Navigate**
```bash
cd medical_note_processor
```

2. **Configure Environment**
```bash
cp .env.example .env
# Edit .env and add your OPENAI_API_KEY
```

3. **Build & Start**
```bash
make build
make up
```

4. **Verify**
```bash
# Health check
curl http://localhost:8000/health
# Expected: {"status": "ok"}

# View logs
make logs
```

### First Steps

```bash
# 1. Check seeded documents
curl http://localhost:8000/documents

# 2. Summarize a medical note
curl -X POST http://localhost:8000/summarize_note \
  -H "Content-Type: application/json" \
  -d '{"text": "Patient presents with chest pain. BP 140/90, HR 88. Prescribed aspirin."}'

# 3. Ask a medical question (RAG)
curl -X POST http://localhost:8000/answer_question \
  -H "Content-Type: application/json" \
  -d '{"question": "What is the first-line treatment for hyperlipidemia?"}'

# 4. Extract structured data from SOAP note
curl -X POST http://localhost:8000/extract_structured \
  -H "Content-Type: application/json" \
  -d @data/soap_notes/soap_02.txt

# 5. Convert to FHIR (use output from step 4 as input)
```

---

## ğŸ“š Implementation Plan

Detailed implementation plans available:

- **[implementation_plan.md](./implementation_plan.md)** - Parts 1-3 (Backend, LLM, RAG)
- **[implementation_plan_parts_4_6.md](./implementation_plan_parts_4_6.md)** - Parts 4-6 (Agent, FHIR, Docker)

Each part includes:
- Requirements checklist (core + stretch goals)
- Complete code implementation
- Unit and integration tests
- Manual testing instructions
- Validation checklist

---

## ğŸ§ª Testing

### Run All Tests
```bash
make test
```

### Test Individual Parts
```bash
# Part 1: Backend
docker-compose exec api pytest tests/test_part1.py -v

# Part 2: LLM
docker-compose exec api pytest tests/test_part2.py -v

# Part 3: RAG
docker-compose exec api pytest tests/test_part3.py -v

# Part 4: Agent
docker-compose exec api pytest tests/test_part4.py -v

# Part 5: FHIR
docker-compose exec api pytest tests/test_part5.py -v

# Part 6: Docker
pytest tests/test_part6.py -v
```

### Custom Evaluations
```bash
# RAG evaluation (golden test set)
docker-compose exec api pytest tests/evaluation/test_rag_eval.py -v

# Agent evaluation (extraction accuracy, code lookup)
docker-compose exec api pytest tests/evaluation/test_agent_eval.py -v
```

### Manual Testing
See [docs/API_EXAMPLES.md](./docs/API_EXAMPLES.md) for curl examples.

---

## ğŸ“– API Documentation

### Part 1: Core Endpoints

#### GET /health
Health check endpoint that returns system status.

**Response:**
```json
{"status": "ok"}
```

#### GET /documents
Fetch list of all document IDs.

**Response:**
```json
[1, 2, 3, 4, 5, 6]
```

#### GET /documents/{document_id}
Fetch a specific document by ID.

#### POST /documents
Create a new document.

#### PUT /documents/{document_id}
Update a document (supports partial updates).

#### DELETE /documents/{document_id}
Delete a document.

### Part 2: LLM Endpoints

#### POST /summarize_note
Summarize a medical note using LLM with automatic caching.

**Request (with document_id):**
```json
{
  "document_id": 1
}
```

**Request (with raw text):**
```json
{
  "text": "Patient presents with chest pain, BP 140/90..."
}
```

**Response:**
```json
{
  "summary": "Patient: 45M, presents with chest pain...",
  "cached": false,
  "provider": "openai",
  "model": "gpt-5.1"
}
```

#### POST /query_note
Ask specific questions about a medical note.

**Request:**
```json
{
  "document_id": 2,
  "query": "What medications were prescribed?"
}
```

**Response:**
```json
{
  "answer": "The patient was prescribed Lisinopril 10mg daily...",
  "cached": false,
  "provider": "openai",
  "model": "gpt-5.1"
}
```

**Note:** Both endpoints support `document_id` (preferred) or `text` (fallback). If both are provided, `document_id` takes priority.

### Configuration

**Environment Variables (.env):**
```env
# Database
DATABASE_URL=postgresql://medical_user:medical_pass@localhost:5432/medical_notes

# LLM Provider
LLM_PROVIDER=openai  # or 'anthropic'
LLM_MODEL=gpt-5.1    # or 'claude-sonnet-4-5'
LLM_API_KEY=your_api_key_here
```

**Switching Providers:**
- OpenAI: Set `LLM_PROVIDER=openai` and use your OpenAI API key
- Anthropic: Set `LLM_PROVIDER=anthropic` and use your Anthropic API key

Both providers use the same `LLM_API_KEY` environment variable.

## ğŸ“– API Documentation

### Base URL
```
http://localhost:8000
```

### Endpoints

#### Part 1: Backend
- `GET /health` - Health check
- `GET /documents` - List all document IDs
- `POST /documents` - Create new document
- `GET /documents/{id}` - Get document by ID
- `PUT /documents/{id}` - Update document (partial updates supported)
- `DELETE /documents/{id}` - Delete document

#### Part 2: LLM
- `POST /summarize_note` - Summarize medical note
  ```json
  {
    "text": "Medical note content..."
  }
  ```

#### Part 3: RAG
- `POST /answer_question` - Answer question from medical guidelines
  ```json
  {
    "question": "What is the treatment for diabetes?"
  }
  ```

#### Part 4: Agent
- `POST /extract_structured` - Extract structured data from SOAP note
  ```json
  {
    "text": "SOAP note content..."
  }
  ```

#### Part 5: FHIR
- `POST /to_fhir` - Convert structured data to FHIR Bundle
  ```json
  {
    "patient": {...},
    "conditions": [...],
    "medications": [...]
  }
  ```

### Interactive Documentation
- **Swagger UI**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc

---

## ğŸ—‚ï¸ Project Structure

```
medical_note_processor/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.py                 # FastAPI application
â”‚   â”œâ”€â”€ config.py               # Pydantic Settings
â”‚   â”œâ”€â”€ database.py             # SQLAlchemy setup
â”‚   â”œâ”€â”€ models.py               # ORM models
â”‚   â”œâ”€â”€ schemas.py              # Pydantic schemas
â”‚   â”œâ”€â”€ providers/              # Provider-agnostic LLM & embeddings
â”‚   â”‚   â”œâ”€â”€ llm/
â”‚   â”‚   â”‚   â”œâ”€â”€ base.py
â”‚   â”‚   â”‚   â”œâ”€â”€ openai.py
â”‚   â”‚   â”‚   â”œâ”€â”€ ollama.py
â”‚   â”‚   â”‚   â””â”€â”€ factory.py
â”‚   â”‚   â””â”€â”€ embeddings/
â”‚   â”‚       â”œâ”€â”€ base.py
â”‚   â”‚       â”œâ”€â”€ openai.py
â”‚   â”‚       â””â”€â”€ factory.py
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â””â”€â”€ summarization.py   # Summarization service
â”‚   â”œâ”€â”€ rag/
â”‚   â”‚   â”œâ”€â”€ chunking.py         # Document chunking
â”‚   â”‚   â”œâ”€â”€ vector_store.py     # ChromaDB wrapper
â”‚   â”‚   â”œâ”€â”€ retriever.py        # Retrieval + reranking
â”‚   â”‚   â””â”€â”€ pipeline.py         # RAG orchestration
â”‚   â”œâ”€â”€ agent/
â”‚   â”‚   â”œâ”€â”€ schemas.py          # Pydantic models for extraction
â”‚   â”‚   â”œâ”€â”€ extractors.py       # LLM entity extraction
â”‚   â”‚   â”œâ”€â”€ api_clients.py      # NIH API clients
â”‚   â”‚   â”œâ”€â”€ validator.py        # Validation logic
â”‚   â”‚   â””â”€â”€ orchestrator.py     # Agent pipeline
â”‚   â””â”€â”€ fhir/
â”‚       â”œâ”€â”€ mappers.py          # FHIR resource mappers
â”‚       â””â”€â”€ bundler.py          # FHIR Bundle creator
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_part1.py           # Backend tests
â”‚   â”œâ”€â”€ test_part2.py           # LLM tests
â”‚   â”œâ”€â”€ test_part3.py           # RAG tests
â”‚   â”œâ”€â”€ test_part4.py           # Agent tests
â”‚   â”œâ”€â”€ test_part5.py           # FHIR tests
â”‚   â”œâ”€â”€ test_part6.py           # Docker tests
â”‚   â”œâ”€â”€ evaluation/
â”‚   â”‚   â”œâ”€â”€ test_rag_eval.py    # RAG evaluation
â”‚   â”‚   â””â”€â”€ test_agent_eval.py  # Agent evaluation
â”‚   â””â”€â”€ golden_sets/
â”‚       â”œâ”€â”€ rag_qa_pairs.json          # RAG test data
â”‚       â””â”€â”€ agent_ground_truth.json    # Agent test data
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ soap_notes/             # 6 SOAP notes from assessment
â”‚   â”‚   â”œâ”€â”€ soap_01.txt
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ medical_guidelines/     # RAG knowledge base
â”‚       â”œâ”€â”€ diabetes_management.md
â”‚       â”œâ”€â”€ hyperlipidemia_treatment.md
â”‚       â””â”€â”€ post_surgical_care.md
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ seed_database.py        # Seed SOAP notes
â”‚   â””â”€â”€ index_documents.py      # Index guidelines for RAG
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ take_home.md                      # Original assessment
â”‚   â”œâ”€â”€ implementation_plan.md            # Parts 1-3 implementation
â”‚   â”œâ”€â”€ implementation_plan_parts_4_6.md  # Parts 4-6 implementation
â”‚   â””â”€â”€ API_EXAMPLES.md                   # Curl examples
â”œâ”€â”€ Dockerfile                  # Multi-stage build
â”œâ”€â”€ docker-compose.yml          # Service orchestration
â”œâ”€â”€ Makefile                    # Common commands
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ .env.example                # Environment template
â”œâ”€â”€ .dockerignore
â””â”€â”€ README.md                   # This file
```

---

## ğŸ› ï¸ Makefile Commands

```bash
make help      # Show all commands
make build     # Build Docker images
make up        # Start all services
make down      # Stop all services
make logs      # View API logs
make test      # Run all tests
make seed      # Seed database
make index     # Index documents for RAG
make clean     # Remove containers & volumes
```

---

## ğŸ”§ Configuration

### Environment Variables

| Variable | Description | Default |
|----------|-------------|---------|
| `DATABASE_URL` | PostgreSQL connection string | `postgresql://...` |
| `LLM_PROVIDER` | LLM provider ('openai' or 'ollama') | `openai` |
| `LLM_MODEL` | LLM model name | `gpt-4-turbo` |
| `OPENAI_API_KEY` | OpenAI API key | (required) |
| `EMBEDDING_PROVIDER` | Embedding provider | `openai` |
| `EMBEDDING_MODEL` | Embedding model | `text-embedding-3-small` |
| `CHUNK_SIZE` | RAG chunk size in tokens | `500` |
| `CHUNK_OVERLAP` | RAG chunk overlap in tokens | `100` |
| `ENABLE_LLM_CACHE` | Enable response caching | `true` |

### Using Ollama (Local LLM)

```bash
# In .env
LLM_PROVIDER=ollama
OLLAMA_BASE_URL=http://host.docker.internal:11434
OLLAMA_MODEL=llama2

EMBEDDING_PROVIDER=ollama
```

---

## ğŸ¥ Medical Guidelines

Three comprehensive medical guidelines are included for the RAG system:

1. **Diabetes Management** (~1500 words)
   - Type 2 diabetes diagnosis and monitoring
   - Medication protocols (Metformin, GLP-1 agonists, insulin)
   - Lifestyle modifications

2. **Hyperlipidemia Treatment** (~1500 words)
   - Cholesterol screening guidelines
   - Statin therapy protocols
   - Risk stratification

3. **Post-Surgical Care** (~1200 words)
   - Post-operative monitoring
   - Wound care
   - Physical therapy protocols

---

## ğŸ“Š Evaluation Criteria

### Correctness & Completeness
- âœ… All 6 parts implemented with stretch goals
- âœ… Direct NIH API integration (ICD-10, RxNorm)
- âœ… Provider-agnostic LLM/embedding architecture
- âœ… RAG with source citations
- âœ… FHIR library usage
- âœ… Comprehensive testing

### Documentation & Setup
- âœ… Single command deployment (`docker-compose up`)
- âœ… Clear README with examples
- âœ… API documentation (Swagger, curl examples)
- âœ… Implementation plan for each part

### Creativity
- âœ… Pydantic Settings for config management
- âœ… Factory pattern for provider abstraction
- âœ… LLM-based reranking in RAG
- âœ… Trajectory logging in agent
- âœ… Custom evaluation frameworks

### Model Agnostic
- âœ… Abstract provider interfaces
- âœ… OpenAI + Ollama support
- âœ… Config-driven model selection
- âœ… Tested with OpenAI (as required for grading)

---

## ğŸ› Troubleshooting

### Services won't start
```bash
# Check logs
make logs

# Rebuild
make clean
make build
make up
```

### Database connection issues
```bash
# Check PostgreSQL is healthy
docker-compose ps

# Reset database
make down
docker volume rm medical_note_processor_postgres_data
make up
```

### RAG not returning results
```bash
# Re-index documents
make index

# Check ChromaDB data
docker-compose exec api python -c "from src.rag.vector_store import VectorStore; vs = VectorStore(); print(vs.collection.count())"
```

### API key errors
```bash
# Verify .env file
cat .env | grep OPENAI_API_KEY

# Restart services after changing .env
make down
make up
```

---

## ğŸ“ License

This project is created for a take-home assessment.

---

## ğŸ™ Acknowledgments

- **SOAP Notes**: Provided in assessment materials
- **NIH APIs**: ICD-10 (ClinicalTables), RxNorm
- **FHIR**: fhir.resources library
- **LLM Providers**: OpenAI, Ollama

---

## ğŸ“§ Contact

For questions about this implementation, please refer to the detailed implementation plans in the `docs/` directory.
